profile = ${profile}

source.hdfs.location.pattern = /home/hadoop/wiki/n_pagecounts-201601%02d-%02d0000

data.table.schema = wiki_ada
data.table.name = pagecounts
data.table.hdfs.location = /home/hadoop/spark/wiki_ada_pagecounts

batch.table.name = pagecounts_batch

sample.table.schema = wiki_ada_verdict
sample.init.ratio = 10
sample.init.type = uniform,stratified
sample.init.stratified.column = project_name
sample.running.type = uniform,stratified

spark.executor.memory = 16g
spark.driver.memory = 4g
spark.sql.warehouse.dir = hdfs://master:9000/home/hadoop/spark/

exp.hour.start = 23
exp.hour.total = 48
exp.hour.interval = 1