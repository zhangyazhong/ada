profile = ${profile}

source.hdfs.location.pattern = /zyz/wiki/n_pagecounts-201601%02d-%02d0000

data.table.schema = wiki_ada
data.table.name = pagecounts
data.table.hdfs.location = /zyz/spark/wiki_ada_pagecounts

batch.table.name = pagecounts_batch

sample.table.schema = wiki_ada_verdict
sample.init.ratio = 10
sample.init.type = uniform,stratified
sample.init.stratified.column = project_name
sample.running.type = uniform,stratified

spark.executor.memory = 64g
spark.driver.memory = 32g
spark.sql.warehouse.dir = hdfs://ubuntu1:9000/zyz/spark/

exp.hour.start = 23
exp.hour.total = 48
exp.hour.interval = 1